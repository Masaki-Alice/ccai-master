{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install faster-whisper\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# %pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIA_SOURCE = \"/var/www/ccai/data-manager/public/audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"LANGUAGE: en\", \"PROBABILITY: 98%\", \"[0.47s -> 3.35s]  Thank you for calling Martha's Flowers. How may I assist you?\", \"[3.79s -> 7.27s]  Hello, I'd like to order flowers and I think you have what I'm looking for.\", \"[7.73s -> 10.61s]  I'd be happy to take care of your order. May I have your name, please?\", \"[11.15s -> 11.95s]  Randall Thomas.\", \"[12.67s -> 14.93s]  Randall Thomas. Can you spell that for me?\", \"[15.63s -> 22.11s]  Randall, R-A-N-D-A-L-L, Thomas, T-H-O-M-A-S.\", \"[22.75s -> 27.11s]  Thank you for that information, Randall. May I have your home or office number area code first?\", \"[27.11s -> 33.67s]  Area code 409, then 866-5088.\", \"[34.33s -> 40.49s]  That's 409-866-5088. Do you have a fax number or email address?\", \"[41.21s -> 46.37s]  My email is randall.thomas at gmail.com.\", \"[46.97s -> 51.49s]  randall.thomas at gmail.com. May I have your shipping address?\", \"[51.49s -> 57.09s]  6800 Gladys Avenue, Beaumont, Texas.\", \"[57.11s -> 61.05s]  Zip code is 77706.\", \"[61.53s -> 66.47s]  Gladys Avenue, Beaumont, Texas. Zip code is 77706.\", \"[66.77s -> 70.37s]  Thank you for the information. What products are you interested in purchasing?\", \"[71.15s -> 72.87s]  Red roses. Probably a dozen.\", \"[73.95s -> 76.49s]  One dozen of red roses? Do you want long stems?\", \"[76.77s -> 77.01s]  Sure.\", \"[77.73s -> 81.09s]  All right. Randall, let me process your order. One moment, please.\", \"[82.21s -> 82.81s]  Okay.\", \"[84.93s -> 88.37s]  Randall, we are ordering one dozen long stemmed red roses.\", \"[88.55s -> 93.79s]  The total amount of your order is $40, and it will be shipped to your address within 24 hours.\", \"[94.29s -> 96.45s]  How soon can you deliver my roses again?\", \"[96.89s -> 98.17s]  Within 24 hours.\", \"[98.63s -> 99.57s]  Okay. No problem.\", \"[100.23s -> 101.91s]  Is there anything else I can help you with?\", \"[102.53s -> 103.83s]  That's all for now. Thanks.\", \"[104.39s -> 107.79s]  No problem, Randall. Thank you for calling Martha's Florist. Have a nice day.\", \"[108.93s -> 109.61s]  Thank you.\", \"[109.61s -> 109.63s]  Thank you.\", \"[109.63s -> 109.65s]  Thank you.\", \"[109.65s -> 109.67s]  Thank you.\", \"[109.67s -> 109.71s]  Thank you.\", \"[109.71s -> 109.75s]  Thank you.\", \"[109.75s -> 109.81s]  Thank you.\", \"[109.81s -> 109.89s]  Thank you.\"]\n",
      "SUCCESS => Transcript saved at ...\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "import os\n",
    "import multiprocessing\n",
    "import json\n",
    "\n",
    "model_size = \"large-v3\"\n",
    "device = \"cuda\"\n",
    "\n",
    "files = [\n",
    "    file\n",
    "    for file in os.listdir(MEDIA_SOURCE)\n",
    "    if os.path.isfile(f\"{MEDIA_SOURCE}/{file}\")\n",
    "]\n",
    "\n",
    "\n",
    "def work(file):\n",
    "    transcript = []\n",
    "    model = WhisperModel(model_size, device=device, compute_type=\"float16\")\n",
    "    segments, info = model.transcribe(\n",
    "        f\"{MEDIA_SOURCE}/{file}\",\n",
    "        beam_size=10,\n",
    "        without_timestamps=False,\n",
    "        vad_filter=True,\n",
    "    )\n",
    "\n",
    "    transcript.append(f\"LANGUAGE: {info.language}\")\n",
    "    transcript.append(f\"PROBABILITY: {round(info.language_probability*100)}%\")\n",
    "\n",
    "    for segment in segments:\n",
    "        transcript.append(\n",
    "            \"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text)\n",
    "        )\n",
    "\n",
    "    # write transcript to file\n",
    "    print(json.dumps(transcript))\n",
    "    # t_file = f\"{MEDIA_SOURCE}/TRANSCRIPT_{file}.txt\"\n",
    "    # with open(t_file, \"a+\") as transcript:\n",
    "\n",
    "    print(f\"SUCCESS => Transcript saved at ...\")\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # pool = multiprocessing.Pool(processes=2)\n",
    "\n",
    "    # for file in files:\n",
    "    #     print(f'START => Transcribing {file}...')\n",
    "    #     p = multiprocessing.Process(target=work, args=(file,)).start()\n",
    "    # pool.apply_async(func=work, args=(file,))\n",
    "\n",
    "    # pool.close()\n",
    "    # pool.join()\n",
    "\n",
    "    work(\"y2mate.com - Sample Order Taking  Customer Support Philippines.mp3\")\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
