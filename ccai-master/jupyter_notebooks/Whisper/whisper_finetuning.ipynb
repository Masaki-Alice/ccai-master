{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "75b58048-7d14-4fc6-8085-1fc08c81b4a6",
      "metadata": {
        "id": "75b58048-7d14-4fc6-8085-1fc08c81b4a6"
      },
      "source": [
        "# Fine-Tune Whisper For Multilingual ASR with 🤗 Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbfa8ad5-4cdc-4512-9058-836cbbf65e1a",
      "metadata": {
        "id": "fbfa8ad5-4cdc-4512-9058-836cbbf65e1a"
      },
      "source": [
        "In this Colab, we present a step-by-step guide on how to fine-tune Whisper\n",
        "for any multilingual ASR dataset using Hugging Face 🤗 Transformers. This is a\n",
        "more \"hands-on\" version of the accompanying [blog post](https://huggingface.co/blog/fine-tune-whisper).\n",
        "For a more in-depth explanation of Whisper, the Common Voice dataset and the theory behind fine-tuning, the reader is advised to refer to the blog post."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe0d503-ae4e-4aa7-9af4-dbcba52db41e",
      "metadata": {
        "id": "afe0d503-ae4e-4aa7-9af4-dbcba52db41e"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ae91ed4-9c3e-4ade-938e-f4c2dcfbfdc0",
      "metadata": {
        "id": "9ae91ed4-9c3e-4ade-938e-f4c2dcfbfdc0"
      },
      "source": [
        "Whisper is a pre-trained model for automatic speech recognition (ASR)\n",
        "published in [September 2022](https://openai.com/blog/whisper/) by the authors\n",
        "Alec Radford et al. from OpenAI. Unlike many of its predecessors, such as\n",
        "[Wav2Vec 2.0](https://arxiv.org/abs/2006.11477), which are pre-trained\n",
        "on un-labelled audio data, Whisper is pre-trained on a vast quantity of\n",
        "**labelled** audio-transcription data, 680,000 hours to be precise.\n",
        "This is an order of magnitude more data than the un-labelled audio data used\n",
        "to train Wav2Vec 2.0 (60,000 hours). What is more, 117,000 hours of this\n",
        "pre-training data is multilingual ASR data. This results in checkpoints\n",
        "that can be applied to over 96 languages, many of which are considered\n",
        "_low-resource_.\n",
        "\n",
        "When scaled to 680,000 hours of labelled pre-training data, Whisper models\n",
        "demonstrate a strong ability to generalise to many datasets and domains.\n",
        "The pre-trained checkpoints achieve competitive results to state-of-the-art\n",
        "ASR systems, with near 3% word error rate (WER) on the test-clean subset of\n",
        "LibriSpeech ASR and a new state-of-the-art on TED-LIUM with 4.7% WER (_c.f._\n",
        "Table 8 of the [Whisper paper](https://cdn.openai.com/papers/whisper.pdf)).\n",
        "The extensive multilingual ASR knowledge acquired by Whisper during pre-training\n",
        "can be leveraged for other low-resource languages; through fine-tuning, the\n",
        "pre-trained checkpoints can be adapted for specific datasets and languages\n",
        "to further improve upon these results. We'll show just how Whisper can be fine-tuned\n",
        "for low-resource languages in this Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e59b91d6-be24-4b5e-bb38-4977ea143a72",
      "metadata": {
        "id": "e59b91d6-be24-4b5e-bb38-4977ea143a72"
      },
      "source": [
        "<figure>\n",
        "<img src=\"https://raw.githubusercontent.com/sanchit-gandhi/notebooks/main/whisper_architecture.svg\" alt=\"Trulli\" style=\"width:30%\">\n",
        "<figcaption align = \"center\"><b>Figure 1:</b> Whisper model. The architecture\n",
        "follows the standard Transformer-based encoder-decoder model. A\n",
        "log-Mel spectrogram is input to the encoder. The last encoder\n",
        "hidden states are input to the decoder via cross-attention mechanisms. The\n",
        "decoder autoregressively predicts text tokens, jointly conditional on the\n",
        "encoder hidden states and previously predicted tokens. Figure source:\n",
        "<a href=\"https://openai.com/blog/whisper/\">OpenAI Whisper Blog</a>.</figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21b6316e-8a55-4549-a154-66d3da2ab74a",
      "metadata": {
        "id": "21b6316e-8a55-4549-a154-66d3da2ab74a"
      },
      "source": [
        "The Whisper checkpoints come in five configurations of varying model sizes.\n",
        "The smallest four are trained on either English-only or multilingual data.\n",
        "The largest checkpoints are multilingual only. All 11 of the pre-trained checkpoints\n",
        "are available on the [Hugging Face Hub](https://huggingface.co/models?search=openai/whisper). The\n",
        "checkpoints are summarised in the following table with links to the models on the Hub:\n",
        "\n",
        "| Size     | Layers | Width | Heads | Parameters | English-only                                         | Multilingual                                        |\n",
        "|----------|--------|-------|-------|------------|------------------------------------------------------|-----------------------------------------------------|\n",
        "| tiny     | 4      | 384   | 6     | 39 M       | [✓](https://huggingface.co/openai/whisper-tiny.en)   | [✓](https://huggingface.co/openai/whisper-tiny.)    |\n",
        "| base     | 6      | 512   | 8     | 74 M       | [✓](https://huggingface.co/openai/whisper-base.en)   | [✓](https://huggingface.co/openai/whisper-base)     |\n",
        "| small    | 12     | 768   | 12    | 244 M      | [✓](https://huggingface.co/openai/whisper-small.en)  | [✓](https://huggingface.co/openai/whisper-small)    |\n",
        "| medium   | 24     | 1024  | 16    | 769 M      | [✓](https://huggingface.co/openai/whisper-medium.en) | [✓](https://huggingface.co/openai/whisper-medium)   |\n",
        "| large    | 32     | 1280  | 20    | 1550 M     | x                                                    | [✓](https://huggingface.co/openai/whisper-large)    |\n",
        "| large-v2 | 32     | 1280  | 20    | 1550 M     | x                                                    | [✓](https://huggingface.co/openai/whisper-large-v2) |\n",
        "| large-v3 | 32     | 1280  | 20    | 1550 M     | x                                                    | [✓](https://huggingface.co/openai/whisper-large-v3) |\n",
        "\n",
        "\n",
        "For demonstration purposes, we'll fine-tune the multilingual version of the\n",
        "[`\"small\"`](https://huggingface.co/openai/whisper-small) checkpoint with 244M params (~= 1GB).\n",
        "As for our data, we'll train and evaluate our system on a low-resource language\n",
        "taken from the [Common Voice](https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0)\n",
        "dataset. We'll show that with as little as 8 hours of fine-tuning data, we can achieve\n",
        "strong performance in this language."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a680dfc-cbba-4f6c-8a1f-e1a5ff3f123a",
      "metadata": {
        "id": "3a680dfc-cbba-4f6c-8a1f-e1a5ff3f123a"
      },
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "\\\\({}^1\\\\) The name Whisper follows from the acronym “WSPSR”, which stands for “Web-scale Supervised Pre-training for Speech Recognition”."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55fb8d21-df06-472a-99dd-b59567be6dad",
      "metadata": {
        "id": "55fb8d21-df06-472a-99dd-b59567be6dad"
      },
      "source": [
        "## Prepare Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "844a4861-929c-4762-b29b-80b1e95aba4b",
      "metadata": {
        "id": "844a4861-929c-4762-b29b-80b1e95aba4b"
      },
      "source": [
        "First of all, let's try to secure a decent GPU for our Colab! Unfortunately, it's becoming much harder to get access to a good GPU with the free version of Google Colab. However, with Google Colab Pro one should have no issues in being allocated a V100 or P100 GPU.\n",
        "\n",
        "To get a GPU, click _Runtime_ -> _Change runtime type_, then change _Hardware accelerator_ from _CPU_ to one of the available GPUs, e.g. _T4_ (or better if you have one available). Next, click `Connect T4` in the top right-hand corner of your screen (or `Connect {V100, A100}` if you selected a different GPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9abea5d7-9d54-434b-a6bd-399d1b3c6c1a",
      "metadata": {
        "id": "9abea5d7-9d54-434b-a6bd-399d1b3c6c1a"
      },
      "source": [
        "We can verify that we've been assigned a GPU and view its specifications:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "95048026-a3b7-43f0-a274-1bad65e407b4",
      "metadata": {
        "id": "95048026-a3b7-43f0-a274-1bad65e407b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: nvidia-smi\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d85d613-1c7e-46ac-9134-660bbe7ebc9d",
      "metadata": {
        "id": "1d85d613-1c7e-46ac-9134-660bbe7ebc9d"
      },
      "source": [
        "We'll employ several popular Python packages to fine-tune the Whisper model.\n",
        "We'll use `datasets[audio]` to download and prepare our training data, alongside\n",
        "`transformers` and `accelerate` to load and train our Whisper model.\n",
        "We'll also require the `soundfile` package to pre-process audio files,\n",
        "`evaluate` and `jiwer` to assess the performance of our model, and\n",
        "`tensorboard` to log our metrics. Finally, we'll use `gradio` to build a\n",
        "flashy demo of our fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e68ea9f8-9b61-414e-8885-3033b67c2850",
      "metadata": {
        "id": "e68ea9f8-9b61-414e-8885-3033b67c2850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            " - defaults\n",
            "Platform: osx-64\n",
            "Collecting package metadata (repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /opt/anaconda3\n",
            "\n",
            "  added / updated specs:\n",
            "    - accelerate\n",
            "    - datasets\n",
            "    - evaluate\n",
            "    - gradio\n",
            "    - jiwer\n",
            "    - tensorboard\n",
            "    - transformers\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    absl-py-2.1.0              |     pyhd8ed1ab_0         105 KB  conda-forge\n",
            "    accelerate-0.29.2          |     pyhd8ed1ab_0         193 KB  conda-forge\n",
            "    annotated-types-0.6.0      |     pyhd8ed1ab_0          17 KB  conda-forge\n",
            "    cachecontrol-0.13.1        |     pyhd8ed1ab_0          23 KB  conda-forge\n",
            "    cachecontrol-with-filecache-0.13.1|     pyhd8ed1ab_0           6 KB  conda-forge\n",
            "    cached-property-1.5.2      |       hd8ed1ab_1           4 KB  conda-forge\n",
            "    cached_property-1.5.2      |     pyha770c72_1          11 KB  conda-forge\n",
            "    cleo-2.0.1                 |     pyhd8ed1ab_0          57 KB  conda-forge\n",
            "    conda-build-3.27.0         |  py311h6eed73b_0         792 KB  conda-forge\n",
            "    datasets-2.19.0            |     pyhd8ed1ab_0         351 KB  conda-forge\n",
            "    evaluate-0.4.1             |     pyhd8ed1ab_0          61 KB  conda-forge\n",
            "    ffmpy-0.3.0                |     pyhb6f538c_0          10 KB  conda-forge\n",
            "    fqdn-1.5.1                 |     pyhd8ed1ab_0          14 KB  conda-forge\n",
            "    gradio-4.28.3              |     pyhd8ed1ab_0         8.9 MB  conda-forge\n",
            "    gradio-client-0.16.0       |     pyhd8ed1ab_0         297 KB  conda-forge\n",
            "    grpcio-1.48.2              |  py311h38f05b6_4         759 KB\n",
            "    huggingface_hub-0.22.2     |     pyhd8ed1ab_0         237 KB  conda-forge\n",
            "    importlib-resources-6.4.0  |     pyhd8ed1ab_0           9 KB  conda-forge\n",
            "    importlib_resources-6.4.0  |     pyhd8ed1ab_0          32 KB  conda-forge\n",
            "    isoduration-20.11.0        |     pyhd8ed1ab_0          17 KB  conda-forge\n",
            "    jiwer-3.0.2                |     pyhd8ed1ab_0          23 KB  conda-forge\n",
            "    jsonschema-4.17.3          |     pyhd8ed1ab_0          69 KB  conda-forge\n",
            "    jsonschema-with-format-nongpl-4.17.3|     pyhd8ed1ab_0           6 KB  conda-forge\n",
            "    jupyter_events-0.6.3       |     pyhd8ed1ab_1          21 KB  conda-forge\n",
            "    jupyterlab_server-2.24.0   |     pyhd8ed1ab_0          59 KB  conda-forge\n",
            "    libuv-1.48.0               |       h67532ce_0         398 KB  conda-forge\n",
            "    multiprocess-0.70.15       |  py311h2725bcf_1         331 KB  conda-forge\n",
            "    ninja-1.12.0               |       h7728843_0         122 KB  conda-forge\n",
            "    orjson-3.10.2              |  py311h2786eb7_0         254 KB  conda-forge\n",
            "    pkgutil-resolve-name-1.3.10|     pyhd8ed1ab_1          11 KB  conda-forge\n",
            "    poetry-1.6.1               | osx_pyh534df25_0         152 KB  conda-forge\n",
            "    poetry-core-1.7.0          |     pyhd8ed1ab_0         296 KB  conda-forge\n",
            "    poetry-plugin-export-1.6.0 |     pyhd8ed1ab_0          16 KB  conda-forge\n",
            "    pyarrow-hotfix-0.6         |     pyhd8ed1ab_0          13 KB  conda-forge\n",
            "    pydantic-2.7.1             |     pyhd8ed1ab_0         276 KB  conda-forge\n",
            "    pydantic-core-2.18.2       |  py311h2786eb7_0         1.5 MB  conda-forge\n",
            "    pyrsistent-0.20.0          |  py311he705e18_0         120 KB  conda-forge\n",
            "    python-build-0.10.0        |     pyhd8ed1ab_1          21 KB  conda-forge\n",
            "    python-multipart-0.0.9     |     pyhd8ed1ab_0          26 KB  conda-forge\n",
            "    python-xxhash-3.4.1        |  py311h2725bcf_0          21 KB  conda-forge\n",
            "    pytorch-1.13.1             |cpu_py311h9e40b02_0        50.1 MB\n",
            "    rapidfuzz-2.13.7           |  py311h814d153_0         1.1 MB  conda-forge\n",
            "    responses-0.18.0           |     pyhd8ed1ab_0          35 KB  conda-forge\n",
            "    ripgrep-14.1.0             |       h11a7dfb_0         1.5 MB  conda-forge\n",
            "    ruff-0.4.2                 |  py311h9220a05_0         5.8 MB  conda-forge\n",
            "    safetensors-0.4.3          |  py311hb69cc6a_0         362 KB  conda-forge\n",
            "    semantic_version-2.10.0    |     pyhd8ed1ab_0          18 KB  conda-forge\n",
            "    tensorboard-2.16.2         |     pyhd8ed1ab_0         4.9 MB  conda-forge\n",
            "    tensorboard-data-server-0.7.0|  py311h892b619_1         3.3 MB  conda-forge\n",
            "    tokenizers-0.19.1          |  py311hf6573bb_0         1.8 MB  conda-forge\n",
            "    tomlkit-0.12.0             |     pyha770c72_0          36 KB  conda-forge\n",
            "    transformers-4.40.1        |     pyhd8ed1ab_0         3.1 MB  conda-forge\n",
            "    typer-0.12.3               |     pyhd8ed1ab_0          51 KB  conda-forge\n",
            "    typer-slim-0.12.3          |     pyhd8ed1ab_0          45 KB  conda-forge\n",
            "    typer-slim-standard-0.12.3 |       hd8ed1ab_0          45 KB  conda-forge\n",
            "    uri-template-1.3.0         |     pyhd8ed1ab_0          23 KB  conda-forge\n",
            "    uvicorn-0.29.0             |  py311h6eed73b_0         126 KB  conda-forge\n",
            "    webcolors-1.13             |     pyhd8ed1ab_0          18 KB  conda-forge\n",
            "    websockets-11.0.3          |  py311h2725bcf_1         196 KB  conda-forge\n",
            "    xattr-0.10.1               |  py311h2725bcf_1          32 KB  conda-forge\n",
            "    xxhash-0.8.2               |       h4140336_0          95 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        88.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  absl-py            conda-forge/noarch::absl-py-2.1.0-pyhd8ed1ab_0 \n",
            "  accelerate         conda-forge/noarch::accelerate-0.29.2-pyhd8ed1ab_0 \n",
            "  annotated-types    conda-forge/noarch::annotated-types-0.6.0-pyhd8ed1ab_0 \n",
            "  cached-property    conda-forge/noarch::cached-property-1.5.2-hd8ed1ab_1 \n",
            "  cached_property    conda-forge/noarch::cached_property-1.5.2-pyha770c72_1 \n",
            "  datasets           conda-forge/noarch::datasets-2.19.0-pyhd8ed1ab_0 \n",
            "  evaluate           conda-forge/noarch::evaluate-0.4.1-pyhd8ed1ab_0 \n",
            "  ffmpy              conda-forge/noarch::ffmpy-0.3.0-pyhb6f538c_0 \n",
            "  fqdn               conda-forge/noarch::fqdn-1.5.1-pyhd8ed1ab_0 \n",
            "  gradio             conda-forge/noarch::gradio-4.28.3-pyhd8ed1ab_0 \n",
            "  gradio-client      conda-forge/noarch::gradio-client-0.16.0-pyhd8ed1ab_0 \n",
            "  grpcio             pkgs/main/osx-64::grpcio-1.48.2-py311h38f05b6_4 \n",
            "  huggingface_hub    conda-forge/noarch::huggingface_hub-0.22.2-pyhd8ed1ab_0 \n",
            "  importlib-resourc~ conda-forge/noarch::importlib-resources-6.4.0-pyhd8ed1ab_0 \n",
            "  importlib_resourc~ conda-forge/noarch::importlib_resources-6.4.0-pyhd8ed1ab_0 \n",
            "  isoduration        conda-forge/noarch::isoduration-20.11.0-pyhd8ed1ab_0 \n",
            "  jiwer              conda-forge/noarch::jiwer-3.0.2-pyhd8ed1ab_0 \n",
            "  jsonschema-with-f~ conda-forge/noarch::jsonschema-with-format-nongpl-4.17.3-pyhd8ed1ab_0 \n",
            "  libuv              conda-forge/osx-64::libuv-1.48.0-h67532ce_0 \n",
            "  multiprocess       conda-forge/osx-64::multiprocess-0.70.15-py311h2725bcf_1 \n",
            "  ninja              conda-forge/osx-64::ninja-1.12.0-h7728843_0 \n",
            "  orjson             conda-forge/osx-64::orjson-3.10.2-py311h2786eb7_0 \n",
            "  pkgutil-resolve-n~ conda-forge/noarch::pkgutil-resolve-name-1.3.10-pyhd8ed1ab_1 \n",
            "  pyarrow-hotfix     conda-forge/noarch::pyarrow-hotfix-0.6-pyhd8ed1ab_0 \n",
            "  pydantic-core      conda-forge/osx-64::pydantic-core-2.18.2-py311h2786eb7_0 \n",
            "  pyrsistent         conda-forge/osx-64::pyrsistent-0.20.0-py311he705e18_0 \n",
            "  python-multipart   conda-forge/noarch::python-multipart-0.0.9-pyhd8ed1ab_0 \n",
            "  python-xxhash      conda-forge/osx-64::python-xxhash-3.4.1-py311h2725bcf_0 \n",
            "  pytorch            pkgs/main/osx-64::pytorch-1.13.1-cpu_py311h9e40b02_0 \n",
            "  responses          conda-forge/noarch::responses-0.18.0-pyhd8ed1ab_0 \n",
            "  ripgrep            conda-forge/osx-64::ripgrep-14.1.0-h11a7dfb_0 \n",
            "  ruff               conda-forge/osx-64::ruff-0.4.2-py311h9220a05_0 \n",
            "  safetensors        conda-forge/osx-64::safetensors-0.4.3-py311hb69cc6a_0 \n",
            "  semantic_version   conda-forge/noarch::semantic_version-2.10.0-pyhd8ed1ab_0 \n",
            "  tensorboard        conda-forge/noarch::tensorboard-2.16.2-pyhd8ed1ab_0 \n",
            "  tensorboard-data-~ conda-forge/osx-64::tensorboard-data-server-0.7.0-py311h892b619_1 \n",
            "  tokenizers         conda-forge/osx-64::tokenizers-0.19.1-py311hf6573bb_0 \n",
            "  transformers       conda-forge/noarch::transformers-4.40.1-pyhd8ed1ab_0 \n",
            "  typer              conda-forge/noarch::typer-0.12.3-pyhd8ed1ab_0 \n",
            "  typer-slim         conda-forge/noarch::typer-slim-0.12.3-pyhd8ed1ab_0 \n",
            "  typer-slim-standa~ conda-forge/noarch::typer-slim-standard-0.12.3-hd8ed1ab_0 \n",
            "  uri-template       conda-forge/noarch::uri-template-1.3.0-pyhd8ed1ab_0 \n",
            "  uvicorn            conda-forge/osx-64::uvicorn-0.29.0-py311h6eed73b_0 \n",
            "  webcolors          conda-forge/noarch::webcolors-1.13-pyhd8ed1ab_0 \n",
            "  websockets         conda-forge/osx-64::websockets-11.0.3-py311h2725bcf_1 \n",
            "  xxhash             conda-forge/osx-64::xxhash-0.8.2-h4140336_0 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  pydantic           pkgs/main/osx-64::pydantic-1.10.12-py~ --> conda-forge/noarch::pydantic-2.7.1-pyhd8ed1ab_0 \n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  conda-build        pkgs/main::conda-build-24.1.2-py311he~ --> conda-forge::conda-build-3.27.0-py311h6eed73b_0 \n",
            "  jsonschema         pkgs/main/osx-64::jsonschema-4.19.2-p~ --> conda-forge/noarch::jsonschema-4.17.3-pyhd8ed1ab_0 \n",
            "  jupyter_events     pkgs/main/osx-64::jupyter_events-0.8.~ --> conda-forge/noarch::jupyter_events-0.6.3-pyhd8ed1ab_1 \n",
            "  jupyterlab_server  pkgs/main/osx-64::jupyterlab_server-2~ --> conda-forge/noarch::jupyterlab_server-2.24.0-pyhd8ed1ab_0 \n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  cachecontrol                          0.14.0-pyhd8ed1ab_0 --> 0.13.1-pyhd8ed1ab_0 \n",
            "  cachecontrol-with~                    0.14.0-pyhd8ed1ab_0 --> 0.13.1-pyhd8ed1ab_0 \n",
            "  cleo                                   2.1.0-pyhd8ed1ab_0 --> 2.0.1-pyhd8ed1ab_0 \n",
            "  poetry                             1.8.2-osx_pyh534df25_0 --> 1.6.1-osx_pyh534df25_0 \n",
            "  poetry-core                            1.9.0-pyhd8ed1ab_0 --> 1.7.0-pyhd8ed1ab_0 \n",
            "  poetry-plugin-exp~                     1.7.1-pyhd8ed1ab_1 --> 1.6.0-pyhd8ed1ab_0 \n",
            "  python-build                           1.2.1-pyhd8ed1ab_0 --> 0.10.0-pyhd8ed1ab_1 \n",
            "  rapidfuzz                           3.8.1-py311hdd0406b_0 --> 2.13.7-py311h814d153_0 \n",
            "  tomlkit                               0.12.4-pyha770c72_0 --> 0.12.0-pyha770c72_0 \n",
            "  xattr                               1.1.0-py311he705e18_0 --> 0.10.1-py311h2725bcf_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "pytorch-1.13.1       | 50.1 MB   |                                       |   0% \n",
            "gradio-4.28.3        | 8.9 MB    |                                       |   0% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    |                                       |   0% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "grpcio-1.48.2        | 759 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuv-1.48.0         | 398 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "safetensors-0.4.3    | 362 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "datasets-2.19.0      | 351 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "multiprocess-0.70.15 | 331 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gradio-client-0.16.0 | 297 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poetry-core-1.7.0    | 296 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-2.7.1       | 276 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orjson-3.10.2        | 254 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "huggingface_hub-0.22 | 237 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "websockets-11.0.3    | 196 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "accelerate-0.29.2    | 193 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   |                                       |   0% [A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    |                                       |   0% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    |                                       |   0% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | 7                                     |   2% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | 3                                     |   1% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | #2                                    |   3% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | 1                                     |   0% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | 1                                     |   0% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | 5                                     |   2% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ##1                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | 2                                     |   1% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | #4                                    |   4% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | 9                                     |   3% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ###1                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | 3                                     |   1% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | 4                                     |   1% \u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #3                                    |   4% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ##2                                   |   6% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ####                                  |  11% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | #####6                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ######3                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #8                                    |   5% \u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ####1                                 |  11% \u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###1                                  |   9% \u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | 5                                     |   2% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ####8                                 |  13% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | 6                                     |   2% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | #######3                              |  20% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | #######1                              |  19% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ########9                             |  24% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | 8                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | 8                                     |   2% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | #########8                            |  27% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###5                                  |  10% \u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ###########                           |  30% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ########2                             |  22% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ###########7                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | 9                                     |   3% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ########9                             |  24% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###8                                  |  10% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ##########5                           |  28% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #                                     |   3% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #1                                    |   3% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ############9                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #1                                    |   3% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ##############1                       |  38% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ###########3                          |  31% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ##############4                       |  39% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ###########8                          |  32% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ####6                                 |  13% \u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ###############2                      |  41% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ############9                         |  35% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #2                                    |   3% \u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #####2                                |  14% \u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #3                                    |   4% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ##############8                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | #################1                    |  46% \u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #3                                    |   4% \u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ##################2                   |  49% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #5                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ######                                |  16% \u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ###################7                  |  54% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ################8                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | #############7                        |  37% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ######3                               |  17% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ##############                        |  38% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | #################5                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #5                                    |   4% \u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ######5                               |  18% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ###############3                      |  42% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #7                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | #####################4                |  58% \u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #######1                              |  19% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ################8                     |  46% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ###################4                  |  53% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | #######################6              |  64% \u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #8                                    |   5% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | #################5                    |  48% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ########################7             |  67% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ####################3                 |  55% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #######6                              |  21% \u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ###########################1          |  73% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #8                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #######8                              |  21% \u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##                                    |   6% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ######################7               |  62% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ###################6                  |  53% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ########4                             |  23% \u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ############################4         |  77% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ####################4                 |  55% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##1                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ########6                             |  23% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ########################3             |  66% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##1                                   |   6% \u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ########9                             |  24% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | #####################                 |  57% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ##########################1           |  71% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ###############################6      |  85% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##3                                   |   6% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #########5                            |  26% \u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ################################6     |  88% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | #######################3              |  63% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #########8                            |  27% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ##########################9           |  73% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##########                            |  27% \u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##4                                   |   6% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ###########################6          |  75% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | #################################5    |  91% \u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##########4                           |  28% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ########################9             |  67% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##5                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ###################################2  |  95% \u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##########7                           |  29% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | #############################4        |  80% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | #########################6            |  69% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##5                                   |   7% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ##############################1       |  81% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ####################################9 | 100% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ##########################2           |  71% \u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ##6                                   |   7% \u001b[A\n",
            "\n",
            "\n",
            "tensorboard-2.16.2   | 4.9 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ##############################6       |  83% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###########2                          |  30% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##7                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | 9                                     |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | #6                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##7                                   |   7% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ###############################1      |  84% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###########4                          |  31% \u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##8                                   |   8% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ##4                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ################################7     |  89% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###########7                          |  32% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ###########################8          |  75% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##8                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ###9                                  |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | #################################2    |  90% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###########9                          |  32% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ####4                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ##9                                   |   8% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ##################################3   |  93% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ############################5         |  77% \u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ##9                                   |   8% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | #######4                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | #############################2        |  79% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ############6                         |  34% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ########1                             |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | #############################5        |  80% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ############8                         |  35% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ########7                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ###1                                  |   9% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ####################################1 |  98% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ##############################2       |  82% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ###########3                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ###1                                  |   9% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ##############################5       |  83% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ####################################6 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ############2                         |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ###2                                  |   9% \u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #############8                        |  38% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ##############################9       |  84% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###3                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ###############################6      |  86% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ###############6                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tensorboard-data-ser | 3.3 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ###############################9      |  86% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##############                        |  38% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###3                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##############2                       |  39% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ################################7     |  89% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###4                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##############6                       |  40% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | 3                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ####################2                 |  55% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###4                                  |   9% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | 9                                     |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##############8                       |  40% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | #####################5                |  58% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | #5                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###5                                  |  10% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###############                       |  41% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ##1                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ######################6               |  61% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | #################################8    |  92% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###############2                      |  41% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###5                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | #######################8              |  64% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ##################################1   |  92% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ###4                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###6                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###############4                      |  42% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ####3                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###6                                  |  10% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | #########################6            |  69% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###############6                      |  42% \u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###6                                  |  10% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ##########################7           |  72% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | #####3                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###############8                      |  43% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | #####9                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ###########################7          |  75% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###7                                  |  10% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###############9                      |  43% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ######5                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###7                                  |  10% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ################                      |  44% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ############################4         |  77% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | #############################2        |  79% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ###################################4  |  96% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###7                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ################2                     |  44% \u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###8                                  |  10% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | #######8                              |  21% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | #############################9        |  81% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ###################################9  |  97% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ################4                     |  44% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ##############################8       |  83% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###8                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ################5                     |  45% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | #########                             |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ###############################8      |  86% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###8                                  |  10% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ################6                     |  45% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | #########7                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ################################5     |  88% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###9                                  |  11% \u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ################8                     |  45% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | #################################2    |  90% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ####################################6 |  99% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###9                                  |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ################9                     |  46% \u001b[A\n",
            "\n",
            "ruff-0.4.2           | 5.8 MB    | ####################################8 | 100% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###9                                  |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ##########9                           |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #################                     |  46% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ##################################7   |  94% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ###9                                  |  11% \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ###########9                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #################2                    |  47% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ###################################8  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ############5                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ####                                  |  11% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####                                  |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #################5                    |  47% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####                                  |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #################7                    |  48% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ##############4                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####1                                 |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | #5                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #################9                    |  48% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####1                                 |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transformers-4.40.1  | 3.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | 3                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ##6                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ################2                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##################1                   |  49% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####2                                 |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##################2                   |  49% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ###8                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ################9                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####2                                 |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##################3                   |  50% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ####6                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | ####7                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | #################5                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ####2                                 |  12% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | #####3                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | ######2                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####2                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | #######4                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##################6                   |  50% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ######1                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ##################7                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####3                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | #######2                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##################8                   |  51% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ###################4                  |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####3                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##################9                   |  51% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ########4                             |  23% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####3                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ####################3                 |  55% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | #########5                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###################1                  |  52% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####4                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ####################9                 |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###################2                  |  52% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ##########7                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | ################                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####4                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###################4                  |  52% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | #################6                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ###########8                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ######################2               |  60% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ####5                                 |  12% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | ###################5                  |  53% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | #############                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####5                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###################7                  |  53% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | #####################1                |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | #######################4              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####5                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###################8                  |  54% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | ######################7               |  61% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ####################                  |  54% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ###############3                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ########################4             |  66% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####6                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | #########################             |  68% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####6                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ################5                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ####################2                 |  55% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####6                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | ############################2         |  76% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ####################3                 |  55% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | #################6                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ####7                                 |  13% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ###################1                  |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ####################7                 |  56% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ##########################3           |  71% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | #############################7        |  80% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ####7                                 |  13% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ####################3                 |  55% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ############################8         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-core-2.18.2 | 1.5 MB    | ################################1     |  87% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #####################1                |  57% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####8                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | #######################               |  62% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | #############################7        |  80% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ####8                                 |  13% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ##############################6       |  83% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ########################5             |  66% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ####9                                 |  13% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ###############################6      |  85% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | #########################7            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #####################7                |  59% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ####9                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ##########################8           |  73% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #####################8                |  59% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####                                 |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | 5                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ############################          |  76% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ######################                |  60% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####                                 |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ######################2               |  60% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ##################################4   |  93% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | #############################1        |  79% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | ###5                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ######################3               |  60% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####                                 |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | #####                                 |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ##############################3       |  82% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ######################4               |  61% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ###################################7  |  96% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | ######5                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####1                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ####################################3 |  98% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | ########                              |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ######################6               |  61% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####1                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizers-0.19.1    | 1.8 MB    | ####################################9 | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | ##########1                           |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ######################8               |  62% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | #################################     |  89% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####1                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####2                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####2                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ######################9               |  62% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | ################1                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####2                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | ##################2                   |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ripgrep-14.1.0       | 1.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #####3                                |  14% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | 7                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####3                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #######################5              |  64% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | ##9                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####4                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #######################7              |  64% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | ########################7             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####4                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | ##########################8           |  72% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #####4                                |  15% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | #######4                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | ############################8         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #####5                                |  15% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | #########7                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####5                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ########################3             |  66% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | ###########9                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####5                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ########################5             |  66% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | ##############2                       |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####6                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | ####################################9 | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "grpcio-1.48.2        | 759 KB    | 7                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ########################7             |  67% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rapidfuzz-2.13.7     | 1.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####6                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #####6                                |  15% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | ##################6                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "grpcio-1.48.2        | 759 KB    | ######2                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####7                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #########################1            |  68% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #####7                                |  16% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | #######################1              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "grpcio-1.48.2        | 759 KB    | ###########6                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #########################4            |  69% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####7                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | ########################6             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | ##########################1           |  71% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #####8                                |  16% \u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #########################6            |  69% \u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #########################8            |  70% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "grpcio-1.48.2        | 759 KB    | #######################3              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuv-1.48.0         | 398 KB    | #4                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "grpcio-1.48.2        | 759 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | ###########################6          |  75% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuv-1.48.0         | 398 KB    | ########9                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #########################9            |  70% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####8                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####9                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##########################            |  70% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####9                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##########################1           |  71% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | ###################################1  |  95% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #####9                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuv-1.48.0         | 398 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-build-3.27.0   | 792 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######                                |  16% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######                                |  16% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######                                |  16% \u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##########################8           |  73% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "datasets-2.19.0      | 351 KB    | #6                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "safetensors-0.4.3    | 362 KB    | #6                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "datasets-2.19.0      | 351 KB    | ########4                             |  23% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######1                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "datasets-2.19.0      | 351 KB    | ###############1                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "multiprocess-0.70.15 | 331 KB    | #####3                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##########################9           |  73% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "safetensors-0.4.3    | 362 KB    | ######5                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######1                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######1                               |  17% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "safetensors-0.4.3    | 362 KB    | #########8                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "datasets-2.19.0      | 351 KB    | #####################9                |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "safetensors-0.4.3    | 362 KB    | ##############7                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######2                               |  17% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######2                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "multiprocess-0.70.15 | 331 KB    | ################1                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###########################5          |  74% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######2                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "datasets-2.19.0      | 351 KB    | ##############################3       |  82% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###########################5          |  75% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "multiprocess-0.70.15 | 331 KB    | ###################6                  |  53% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###########################6          |  75% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "safetensors-0.4.3    | 362 KB    | #####################2                |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######3                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "multiprocess-0.70.15 | 331 KB    | #######################2              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "datasets-2.19.0      | 351 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "datasets-2.19.0      | 351 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "safetensors-0.4.3    | 362 KB    | ########################5             |  66% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######3                               |  17% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "multiprocess-0.70.15 | 331 KB    | ##########################8           |  73% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######3                               |  17% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######3                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "multiprocess-0.70.15 | 331 KB    | ###################################8  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gradio-client-0.16.0 | 297 KB    | #############9                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "multiprocess-0.70.15 | 331 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "safetensors-0.4.3    | 362 KB    | ##########################1           |  71% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ############################3         |  77% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######4                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######4                               |  18% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gradio-client-0.16.0 | 297 KB    | #########################9            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-2.7.1       | 276 KB    | ##1                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######5                               |  18% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gradio-client-0.16.0 | 297 KB    | #################################8    |  92% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-2.7.1       | 276 KB    | ######4                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gradio-client-0.16.0 | 297 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######5                               |  18% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-2.7.1       | 276 KB    | ############8                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######5                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #############################         |  79% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poetry-core-1.7.0    | 296 KB    | #####9                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-2.7.1       | 276 KB    | ###################3                  |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######6                               |  18% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poetry-core-1.7.0    | 296 KB    | #########9                            |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-2.7.1       | 276 KB    | #########################7            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######6                               |  18% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-2.7.1       | 276 KB    | ################################2     |  87% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poetry-core-1.7.0    | 296 KB    | #############9                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orjson-3.10.2        | 254 KB    | ##3                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #############################4        |  80% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######6                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pydantic-2.7.1       | 276 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orjson-3.10.2        | 254 KB    | #########3                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poetry-core-1.7.0    | 296 KB    | #################9                    |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######7                               |  18% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orjson-3.10.2        | 254 KB    | ################3                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poetry-core-1.7.0    | 296 KB    | #####################9                |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #############################7        |  80% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orjson-3.10.2        | 254 KB    | #######################3              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######7                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poetry-core-1.7.0    | 296 KB    | #########################9            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #############################8        |  81% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orjson-3.10.2        | 254 KB    | ##############################3       |  82% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######7                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #############################9        |  81% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poetry-core-1.7.0    | 296 KB    | #############################9        |  81% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orjson-3.10.2        | 254 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "orjson-3.10.2        | 254 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######8                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poetry-core-1.7.0    | 296 KB    | #################################9    |  92% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##############################1       |  82% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######8                               |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poetry-core-1.7.0    | 296 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "huggingface_hub-0.22 | 237 KB    | ###########################4          |  74% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######8                               |  19% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "huggingface_hub-0.22 | 237 KB    | ##################################9   |  94% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##############################5       |  83% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | ######9                               |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "websockets-11.0.3    | 196 KB    | ###                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######9                               |  19% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "websockets-11.0.3    | 196 KB    | ############                          |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "accelerate-0.29.2    | 193 KB    | ###                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ######9                               |  19% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "websockets-11.0.3    | 196 KB    | #####################1                |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "accelerate-0.29.2    | 193 KB    | ######1                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######                               |  19% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "websockets-11.0.3    | 196 KB    | ##############################2       |  82% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ###############################       |  84% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "accelerate-0.29.2    | 193 KB    | ############2                         |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "websockets-11.0.3    | 196 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######                               |  19% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "accelerate-0.29.2    | 193 KB    | ##################3                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######1                              |  19% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "accelerate-0.29.2    | 193 KB    | ########################4             |  66% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######1                              |  19% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "accelerate-0.29.2    | 193 KB    | ##############################6       |  83% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######1                              |  19% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "accelerate-0.29.2    | 193 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.13.1       | 50.1 MB   | #######1                              |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######2                              |  20% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######3                              |  20% \u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ################################6     |  88% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######4                              |  20% \u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | #################################1    |  90% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######5                              |  20% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######5                              |  20% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######6                              |  21% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######7                              |  21% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######7                              |  21% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######8                              |  21% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######8                              |  21% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######8                              |  21% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######9                              |  21% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######9                              |  21% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | #######9                              |  22% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ########                              |  22% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ########                              |  22% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ########                              |  22% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ########2                             |  22% \u001b[A\n",
            "gradio-4.28.3        | 8.9 MB    | ##################################### | 100% \u001b[A\n",
            "pytorch-1.13.1       | 50.1 MB   | ##################################### | 100% \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \n",
            "                                                                                \u001b[A\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: done\n",
            "Verifying transaction: done\n",
            "Executing transaction: done\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%conda install datasets transformers accelerate evaluate jiwer tensorboard gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f60d173-8de1-4ed7-bc9a-d281cf237203",
      "metadata": {
        "id": "1f60d173-8de1-4ed7-bc9a-d281cf237203"
      },
      "source": [
        "We strongly advise you to upload model checkpoints directly the [Hugging Face Hub](https://huggingface.co/)\n",
        "whilst training. The Hub provides:\n",
        "- Integrated version control: you can be sure that no model checkpoint is lost during training.\n",
        "- Tensorboard logs: track important metrics over the course of training.\n",
        "- Model cards: document what a model does and its intended use cases.\n",
        "- Community: an easy way to share and collaborate with the community!\n",
        "\n",
        "Linking the notebook to the Hub is straightforward - it simply requires entering your\n",
        "Hub authentication token when prompted. Find your Hub authentication token [here](https://huggingface.co/settings/tokens):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b045a39e-2a3e-4153-bdb5-281500bcd348",
      "metadata": {
        "id": "b045a39e-2a3e-4153-bdb5-281500bcd348"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a12a08d1cf8436696667d535c4e707e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# 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\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b219c9dd-39b6-4a95-b2a1-3f547a1e7bc0",
      "metadata": {
        "id": "b219c9dd-39b6-4a95-b2a1-3f547a1e7bc0"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "674429c5-0ab4-4adf-975b-621bb69eca38",
      "metadata": {
        "id": "674429c5-0ab4-4adf-975b-621bb69eca38"
      },
      "source": [
        "Using 🤗 Datasets, downloading and preparing data is extremely simple.\n",
        "We can download and prepare the Common Voice splits in just one line of code.\n",
        "\n",
        "First, ensure you have accepted the terms of use on the Hugging Face Hub: [mozilla-foundation/common_voice_11_0](https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0). Once you have accepted the terms, you will have full access to the dataset and be able to download the data locally.\n",
        "\n",
        "Since Hindi is very low-resource, we'll combine the `train` and `validation`\n",
        "splits to give approximately 8 hours of training data. We'll use the 4 hours\n",
        "of `test` data as our held-out test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a2787582-554f-44ce-9f38-4180a5ed6b44",
      "metadata": {
        "id": "a2787582-554f-44ce-9f38-4180a5ed6b44"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, DatasetDict\n\u001b[1;32m      3\u001b[0m common_voice \u001b[38;5;241m=\u001b[39m DatasetDict()\n\u001b[1;32m      5\u001b[0m common_voice[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmozilla-foundation/common_voice_11_0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msw\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain+validation\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sw\", split=\"train+validation\", use_auth_token=True)\n",
        "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"sw\", split=\"test\", use_auth_token=True)\n",
        "\n",
        "print(common_voice)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5c7c3d6-7197-41e7-a088-49b753c1681f",
      "metadata": {
        "id": "d5c7c3d6-7197-41e7-a088-49b753c1681f"
      },
      "source": [
        "Most ASR datasets only provide input audio samples (`audio`) and the\n",
        "corresponding transcribed text (`sentence`). Common Voice contains additional\n",
        "metadata information, such as `accent` and `locale`, which we can disregard for ASR.\n",
        "Keeping the notebook as general as possible, we only consider the input audio and\n",
        "transcribed text for fine-tuning, discarding the additional metadata information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ba635d-518c-47ac-97ee-3cad25f1e0ce",
      "metadata": {
        "id": "20ba635d-518c-47ac-97ee-3cad25f1e0ce"
      },
      "outputs": [],
      "source": [
        "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\n",
        "\n",
        "print(common_voice)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d63b2d2-f68a-4d74-b7f1-5127f6d16605",
      "metadata": {
        "id": "2d63b2d2-f68a-4d74-b7f1-5127f6d16605"
      },
      "source": [
        "## Prepare Feature Extractor, Tokenizer and Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "601c3099-1026-439e-93e2-5635b3ba5a73",
      "metadata": {
        "id": "601c3099-1026-439e-93e2-5635b3ba5a73"
      },
      "source": [
        "The ASR pipeline can be de-composed into three stages:\n",
        "\n",
        "1. A feature extractor which pre-processes the raw audio-inputs\n",
        "2. The model which performs the sequence-to-sequence mapping\n",
        "3. A tokenizer which post-processes the model outputs to text format\n",
        "\n",
        "In 🤗 Transformers, the Whisper model has an associated feature extractor and tokenizer,\n",
        "called [WhisperFeatureExtractor](https://huggingface.co/docs/transformers/main/model_doc/whisper#transformers.WhisperFeatureExtractor)\n",
        "and [WhisperTokenizer](https://huggingface.co/docs/transformers/main/model_doc/whisper#transformers.WhisperTokenizer)\n",
        "respectively.\n",
        "\n",
        "We'll go through details for setting-up the feature extractor and tokenizer one-by-one!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "560332eb-3558-41a1-b500-e83a9f695f84",
      "metadata": {
        "id": "560332eb-3558-41a1-b500-e83a9f695f84"
      },
      "source": [
        "### Load WhisperFeatureExtractor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32ec8068-0bd7-412d-b662-0edb9d1e7365",
      "metadata": {
        "id": "32ec8068-0bd7-412d-b662-0edb9d1e7365"
      },
      "source": [
        "The Whisper feature extractor performs two operations:\n",
        "1. Pads / truncates the audio inputs to 30s: any audio inputs shorter than 30s are padded to 30s with silence (zeros), and those longer that 30s are truncated to 30s\n",
        "2. Converts the audio inputs to _log-Mel spectrogram_ input features, a visual representation of the audio and the form of the input expected by the Whisper model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "589d9ec1-d12b-4b64-93f7-04c63997da19",
      "metadata": {
        "id": "589d9ec1-d12b-4b64-93f7-04c63997da19"
      },
      "source": [
        "<figure>\n",
        "<img src=\"https://raw.githubusercontent.com/sanchit-gandhi/notebooks/main/spectrogram.jpg\" alt=\"Trulli\" style=\"width:100%\">\n",
        "<figcaption align = \"center\"><b>Figure 2:</b> Conversion of sampled audio array to log-Mel spectrogram.\n",
        "Left: sampled 1-dimensional audio signal. Right: corresponding log-Mel spectrogram. Figure source:\n",
        "<a href=\"https://ai.googleblog.com/2019/04/specaugment-new-data-augmentation.html\">Google SpecAugment Blog</a>.\n",
        "</figcaption>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ef54d5-b946-4c1d-9fdc-adc5d01b46aa",
      "metadata": {
        "id": "b2ef54d5-b946-4c1d-9fdc-adc5d01b46aa"
      },
      "source": [
        "We'll load the feature extractor from the pre-trained checkpoint with the default values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc77d7bb-f9e2-47f5-b663-30f7a4321ce5",
      "metadata": {
        "id": "bc77d7bb-f9e2-47f5-b663-30f7a4321ce5"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-medium\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93748af7-b917-4ecf-a0c8-7d89077ff9cb",
      "metadata": {
        "id": "93748af7-b917-4ecf-a0c8-7d89077ff9cb"
      },
      "source": [
        "### Load WhisperTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bc82609-a9fb-447a-a2af-99597c864029",
      "metadata": {
        "id": "2bc82609-a9fb-447a-a2af-99597c864029"
      },
      "source": [
        "The Whisper model outputs a sequence of _token ids_. The tokenizer maps each of these token ids to their corresponding text string. For Hindi, we can load the pre-trained tokenizer and use it for fine-tuning without any further modifications. We simply have to\n",
        "specify the target language and the task. These arguments inform the\n",
        "tokenizer to prefix the language and task tokens to the start of encoded\n",
        "label sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b07f9b-ae0e-4f89-98f0-0c50d432eab6",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "90d056e20b3e4f14ae0199a1a4ab1bb0",
            "d82a88daec0e4f14add691b7b903064c",
            "350acdb0f40e454099fa901e66de55f0",
            "2e6a82a462cc411d90fa1bea4ee60790",
            "c74bfee0198b4817832ea86e8e88d96c",
            "04fb2d81eff646068e10475a08ae42f4"
          ]
        },
        "id": "c7b07f9b-ae0e-4f89-98f0-0c50d432eab6",
        "outputId": "5c004b44-86e7-4e00-88be-39e0af5eed69"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperTokenizer\n",
        "\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-medium\", language=\"swahili\", task=\"transcribe\")\n",
        "\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2ef23f3-f4a8-483a-a2dc-080a7496cb1b",
      "metadata": {
        "id": "d2ef23f3-f4a8-483a-a2dc-080a7496cb1b"
      },
      "source": [
        "### Combine To Create A WhisperProcessor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ff67654-5a29-4bb8-a69d-0228946c6f8d",
      "metadata": {
        "id": "5ff67654-5a29-4bb8-a69d-0228946c6f8d"
      },
      "source": [
        "To simplify using the feature extractor and tokenizer, we can _wrap_\n",
        "both into a single `WhisperProcessor` class. This processor object\n",
        "inherits from the `WhisperFeatureExtractor` and `WhisperProcessor`,\n",
        "and can be used on the audio inputs and model predictions as required.\n",
        "In doing so, we only need to keep track of two objects during training:\n",
        "the `processor` and the `model`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d9f0c5-8607-4642-a8ac-c3ab2e223ea6",
      "metadata": {
        "id": "77d9f0c5-8607-4642-a8ac-c3ab2e223ea6"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\", language=\"swahili\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "381acd09-0b0f-4d04-9eb3-f028ac0e5f2c",
      "metadata": {
        "id": "381acd09-0b0f-4d04-9eb3-f028ac0e5f2c"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9649bf01-2e8a-45e5-8fca-441c13637b8f",
      "metadata": {
        "id": "9649bf01-2e8a-45e5-8fca-441c13637b8f"
      },
      "source": [
        "Let's print the first example of the Common Voice dataset to see\n",
        "what form the data is in:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e6b0ec5-0c94-4e2c-ae24-c791be1b2255",
      "metadata": {
        "id": "6e6b0ec5-0c94-4e2c-ae24-c791be1b2255"
      },
      "outputs": [],
      "source": [
        "(common_voice[\"train\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a679f05-063d-41b3-9b58-4fc9c6ccf4fd",
      "metadata": {
        "id": "5a679f05-063d-41b3-9b58-4fc9c6ccf4fd"
      },
      "source": [
        "Since\n",
        "our input audio is sampled at 48kHz, we need to _downsample_ it to\n",
        "16kHz prior to passing it to the Whisper feature extractor, 16kHz being the sampling rate expected by the Whisper model.\n",
        "\n",
        "We'll set the audio inputs to the correct sampling rate using dataset's\n",
        "[`cast_column`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=cast_column#datasets.DatasetDict.cast_column)\n",
        "method. This operation does not change the audio in-place,\n",
        "but rather signals to `datasets` to resample audio samples _on the fly_ the\n",
        "first time that they are loaded:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f12e2e57-156f-417b-8cfb-69221cc198e8",
      "metadata": {
        "id": "f12e2e57-156f-417b-8cfb-69221cc198e8"
      },
      "outputs": [],
      "source": [
        "from datasets import Audio\n",
        "\n",
        "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00382a3e-abec-4cdd-a54c-d1aaa3ea4707",
      "metadata": {
        "id": "00382a3e-abec-4cdd-a54c-d1aaa3ea4707"
      },
      "source": [
        "Re-loading the first audio sample in the Common Voice dataset will resample\n",
        "it to the desired sampling rate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87122d71-289a-466a-afcf-fa354b18946b",
      "metadata": {
        "id": "87122d71-289a-466a-afcf-fa354b18946b"
      },
      "outputs": [],
      "source": [
        "print(common_voice[\"train\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91edc72d-08f8-4f01-899d-74e65ce441fc",
      "metadata": {
        "id": "91edc72d-08f8-4f01-899d-74e65ce441fc"
      },
      "source": [
        "Now we can write a function to prepare our data ready for the model:\n",
        "1. We load and resample the audio data by calling `batch[\"audio\"]`. As explained above, 🤗 Datasets performs any necessary resampling operations on the fly.\n",
        "2. We use the feature extractor to compute the log-Mel spectrogram input features from our 1-dimensional audio array.\n",
        "3. We encode the transcriptions to label ids through the use of the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6525c478-8962-4394-a1c4-103c54cce170",
      "metadata": {
        "id": "6525c478-8962-4394-a1c4-103c54cce170"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(batch):\n",
        "    # load and resample audio data from 48 to 16kHz\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # compute log-Mel input features from input audio array\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # encode target text to label ids\n",
        "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70b319fb-2439-4ef6-a70d-a47bf41c4a13",
      "metadata": {
        "id": "70b319fb-2439-4ef6-a70d-a47bf41c4a13"
      },
      "source": [
        "We can apply the data preparation function to all of our training examples using dataset's `.map` method. The argument `num_proc` specifies how many CPU cores to use. Setting `num_proc` > 1 will enable multiprocessing. If the `.map` method hangs with multiprocessing, set `num_proc=1` and process the dataset sequentially."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b73ab39-ffaf-4b9e-86e5-782963c6134b",
      "metadata": {
        "id": "7b73ab39-ffaf-4b9e-86e5-782963c6134b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "processes = 1\n",
        "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=processes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "263a5a58-0239-4a25-b0df-c625fc9c5810",
      "metadata": {
        "id": "263a5a58-0239-4a25-b0df-c625fc9c5810"
      },
      "source": [
        "## Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a693e768-c5a6-453f-89a1-b601dcf7daf7",
      "metadata": {
        "id": "a693e768-c5a6-453f-89a1-b601dcf7daf7"
      },
      "source": [
        "Now that we've prepared our data, we're ready to dive into the training pipeline.\n",
        "The [🤗 Trainer](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer)\n",
        "will do much of the heavy lifting for us. All we have to do is:\n",
        "\n",
        "- Load a pre-trained checkpoint: we need to load a pre-trained checkpoint and configure it correctly for training.\n",
        "\n",
        "- Define a data collator: the data collator takes our pre-processed data and prepares PyTorch tensors ready for the model.\n",
        "\n",
        "- Evaluation metrics: during evaluation, we want to evaluate the model using the [word error rate (WER)](https://huggingface.co/metrics/wer) metric. We need to define a `compute_metrics` function that handles this computation.\n",
        "\n",
        "- Define the training configuration: this will be used by the 🤗 Trainer to define the training schedule.\n",
        "\n",
        "Once we've fine-tuned the model, we will evaluate it on the test data to verify that we have correctly trained it\n",
        "to transcribe speech in Hindi."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daf2a825-6d9f-4a23-b145-c37c0039075b",
      "metadata": {
        "id": "daf2a825-6d9f-4a23-b145-c37c0039075b"
      },
      "source": [
        "### Load a Pre-Trained Checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "437a97fa-4864-476b-8abc-f28b8166cfa5",
      "metadata": {
        "id": "437a97fa-4864-476b-8abc-f28b8166cfa5"
      },
      "source": [
        "We'll start our fine-tuning run from the pre-trained Whisper `small` checkpoint,\n",
        "the weights for which we need to load from the Hugging Face Hub. Again, this\n",
        "is trivial through use of 🤗 Transformers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a10cc4b-07ec-4ebd-ac1d-7c601023594f",
      "metadata": {
        "id": "5a10cc4b-07ec-4ebd-ac1d-7c601023594f"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-medium\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a15ead5f-2277-4a39-937b-585c2497b2df",
      "metadata": {
        "id": "a15ead5f-2277-4a39-937b-585c2497b2df"
      },
      "source": [
        "We can disable the automatic language detection task performed during inference, and force the model to generate in Hindi. To do so, we set the [langauge](https://huggingface.co/docs/transformers/en/model_doc/whisper#transformers.WhisperForConditionalGeneration.generate.language)\n",
        "and [task](https://huggingface.co/docs/transformers/en/model_doc/whisper#transformers.WhisperForConditionalGeneration.generate.task)\n",
        "arguments to the generation config. We'll also set any [`forced_decoder_ids`](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.forced_decoder_ids)\n",
        "to None, since this was the legacy way of setting the language and\n",
        "task arguments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62038ba3-88ed-4fce-84db-338f50dcd04f",
      "metadata": {
        "id": "62038ba3-88ed-4fce-84db-338f50dcd04f"
      },
      "outputs": [],
      "source": [
        "model.generation_config.language = \"swahili\"\n",
        "model.generation_config.task = \"transcribe\"\n",
        "\n",
        "model.generation_config.forced_decoder_ids = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d230e6d-624c-400a-bbf5-fa660881df25",
      "metadata": {
        "id": "8d230e6d-624c-400a-bbf5-fa660881df25"
      },
      "source": [
        "### Define a Data Collator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04def221-0637-4a69-b242-d3f0c1d0ee78",
      "metadata": {
        "id": "04def221-0637-4a69-b242-d3f0c1d0ee78"
      },
      "source": [
        "The data collator for a sequence-to-sequence speech model is unique in the sense that it\n",
        "treats the `input_features` and `labels` independently: the  `input_features` must be\n",
        "handled by the feature extractor and the `labels` by the tokenizer.\n",
        "\n",
        "The `input_features` are already padded to 30s and converted to a log-Mel spectrogram\n",
        "of fixed dimension by action of the feature extractor, so all we have to do is convert the `input_features`\n",
        "to batched PyTorch tensors. We do this using the feature extractor's `.pad` method with `return_tensors=pt`.\n",
        "\n",
        "The `labels` on the other hand are un-padded. We first pad the sequences\n",
        "to the maximum length in the batch using the tokenizer's `.pad` method. The padding tokens\n",
        "are then replaced by `-100` so that these tokens are **not** taken into account when\n",
        "computing the loss. We then cut the BOS token from the start of the label sequence as we\n",
        "append it later during training.\n",
        "\n",
        "We can leverage the `WhisperProcessor` we defined earlier to perform both the\n",
        "feature extractor and the tokenizer operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8326221e-ec13-4731-bb4e-51e5fc1486c5",
      "metadata": {
        "id": "8326221e-ec13-4731-bb4e-51e5fc1486c5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "    decoder_start_token_id: int\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cae7dbf-8a50-456e-a3a8-7fd005390f86",
      "metadata": {
        "id": "3cae7dbf-8a50-456e-a3a8-7fd005390f86"
      },
      "source": [
        "Let's initialise the data collator we've just defined:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc834702-c0d3-4a96-b101-7b87be32bf42",
      "metadata": {
        "id": "fc834702-c0d3-4a96-b101-7b87be32bf42"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
        "    processor=processor,\n",
        "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d62bb2ab-750a-45e7-82e9-61d6f4805698",
      "metadata": {
        "id": "d62bb2ab-750a-45e7-82e9-61d6f4805698"
      },
      "source": [
        "### Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66fee1a7-a44c-461e-b047-c3917221572e",
      "metadata": {
        "id": "66fee1a7-a44c-461e-b047-c3917221572e"
      },
      "source": [
        "We'll use the word error rate (WER) metric, the 'de-facto' metric for assessing\n",
        "ASR systems. For more information, refer to the WER [docs](https://huggingface.co/metrics/wer). We'll load the WER metric from 🤗 Evaluate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b22b4011-f31f-4b57-b684-c52332f92890",
      "metadata": {
        "id": "b22b4011-f31f-4b57-b684-c52332f92890"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"wer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f32cab6-31f0-4cb9-af4c-40ba0f5fc508",
      "metadata": {
        "id": "4f32cab6-31f0-4cb9-af4c-40ba0f5fc508"
      },
      "source": [
        "We then simply have to define a function that takes our model\n",
        "predictions and returns the WER metric. This function, called\n",
        "`compute_metrics`, first replaces `-100` with the `pad_token_id`\n",
        "in the `label_ids` (undoing the step we applied in the\n",
        "data collator to ignore padded tokens correctly in the loss).\n",
        "It then decodes the predicted and label ids to strings. Finally,\n",
        "it computes the WER between the predictions and reference labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23959a70-22d0-4ffe-9fa1-72b61e75bb52",
      "metadata": {
        "id": "23959a70-22d0-4ffe-9fa1-72b61e75bb52"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2178dea4-80ca-47b6-b6ea-ba1915c90c06",
      "metadata": {
        "id": "2178dea4-80ca-47b6-b6ea-ba1915c90c06"
      },
      "source": [
        "### Define the Training Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c21af1e9-0188-4134-ac82-defc7bdcc436",
      "metadata": {
        "id": "c21af1e9-0188-4134-ac82-defc7bdcc436"
      },
      "source": [
        "In the final step, we define all the parameters related to training. For more detail on the training arguments, refer to the Seq2SeqTrainingArguments [docs](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a",
      "metadata": {
        "id": "0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./tuned_model\",  # change to a repo name of your choice\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    max_steps=4000,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    save_steps=1000,\n",
        "    eval_steps=1000,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=True,\n",
        "    no_cuda=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a944d8-3112-4552-82a0-be25988b3857",
      "metadata": {
        "id": "b3a944d8-3112-4552-82a0-be25988b3857"
      },
      "source": [
        "**Note**: if one does not want to upload the model checkpoints to the Hub,\n",
        "set `push_to_hub=False`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac29114-d226-4f54-97cf-8718c9f94e1e",
      "metadata": {
        "id": "bac29114-d226-4f54-97cf-8718c9f94e1e"
      },
      "source": [
        "We can forward the training arguments to the 🤗 Trainer along with our model,\n",
        "dataset, data collator and `compute_metrics` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d546d7fe-0543-479a-b708-2ebabec19493",
      "metadata": {
        "id": "d546d7fe-0543-479a-b708-2ebabec19493"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=common_voice[\"train\"],\n",
        "    eval_dataset=common_voice[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uOrRhDGtN5S4",
      "metadata": {
        "id": "uOrRhDGtN5S4"
      },
      "source": [
        "We'll save the processor object once before starting training. Since the processor is not trainable, it won't change over the course of training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-2zQwMfEOBJq",
      "metadata": {
        "id": "-2zQwMfEOBJq"
      },
      "outputs": [],
      "source": [
        "processor.save_pretrained(training_args.output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f404cf9-4345-468c-8196-4bd101d9bd51",
      "metadata": {
        "id": "7f404cf9-4345-468c-8196-4bd101d9bd51"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8b8d56-5a70-4f68-bd2e-f0752d0bd112",
      "metadata": {
        "id": "5e8b8d56-5a70-4f68-bd2e-f0752d0bd112"
      },
      "source": [
        "Training will take approximately 5-10 hours depending on your GPU or the one\n",
        "allocated to this Google Colab. If using this Google Colab directly to\n",
        "fine-tune a Whisper model, you should make sure that training isn't\n",
        "interrupted due to inactivity. A simple workaround to prevent this is\n",
        "to paste the following code into the console of this tab (_right mouse click_\n",
        "-> _inspect_ -> _Console tab_ -> _insert code_)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "890a63ed-e87b-4e53-a35a-6ec1eca560af",
      "metadata": {
        "id": "890a63ed-e87b-4e53-a35a-6ec1eca560af"
      },
      "source": [
        "```javascript\n",
        "function ConnectButton(){\n",
        "    console.log(\"Connect pushed\");\n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
        "}\n",
        "setInterval(ConnectButton, 60000);\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a55168b-2f46-4678-afa0-ff22257ec06d",
      "metadata": {
        "id": "5a55168b-2f46-4678-afa0-ff22257ec06d"
      },
      "source": [
        "The peak GPU memory for the given training configuration is approximately 15.8GB.\n",
        "Depending on the GPU allocated to the Google Colab, it is possible that you will encounter a CUDA `\"out-of-memory\"` error when you launch training.\n",
        "In this case, you can reduce the `per_device_train_batch_size` incrementally by factors of 2\n",
        "and employ [`gradient_accumulation_steps`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments.gradient_accumulation_steps)\n",
        "to compensate.\n",
        "\n",
        "To launch training, simply execute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee8b7b8e-1c9a-4d77-9137-1778a629e6de",
      "metadata": {
        "id": "ee8b7b8e-1c9a-4d77-9137-1778a629e6de"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "810ced54-7187-4a06-b2fe-ba6dcca94dc3",
      "metadata": {
        "id": "810ced54-7187-4a06-b2fe-ba6dcca94dc3"
      },
      "source": [
        "Our best WER is 32.0% - not bad for 8h of training data! We can make our model more accessible on the Hub with appropriate tags and README information.\n",
        "You can change these values to match your dataset, language and model\n",
        "name accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c704f91e-241b-48c9-b8e0-f0da396a9663",
      "metadata": {
        "id": "c704f91e-241b-48c9-b8e0-f0da396a9663"
      },
      "outputs": [],
      "source": [
        "kwargs = {\n",
        "    \"dataset_tags\": \"mozilla-foundation/common_voice_11_0\",\n",
        "    \"dataset\": \"Common Voice 11.0\",  # a 'pretty' name for the training dataset\n",
        "    \"dataset_args\": \"config: hi, split: test\",\n",
        "    \"language\": \"hi\",\n",
        "    \"model_name\": \"Whisper Small Hi - Sanchit Gandhi\",  # a 'pretty' name for our model\n",
        "    \"finetuned_from\": \"openai/whisper-small\",\n",
        "    \"tasks\": \"automatic-speech-recognition\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "090d676a-f944-4297-a938-a40eda0b2b68",
      "metadata": {
        "id": "090d676a-f944-4297-a938-a40eda0b2b68"
      },
      "source": [
        "The training results can now be uploaded to the Hub. To do so, execute the `push_to_hub` command and save the preprocessor object we created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7030622-caf7-4039-939b-6195cdaa2585",
      "metadata": {
        "id": "d7030622-caf7-4039-939b-6195cdaa2585"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(**kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34d4360d-5721-426e-b6ac-178f833fedeb",
      "metadata": {
        "id": "34d4360d-5721-426e-b6ac-178f833fedeb"
      },
      "source": [
        "## Building a Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e65489b7-18d1-447c-ba69-cd28dd80dad9",
      "metadata": {
        "id": "e65489b7-18d1-447c-ba69-cd28dd80dad9"
      },
      "source": [
        "Now that we've fine-tuned our model we can build a demo to show\n",
        "off its ASR capabilities! We'll make use of 🤗 Transformers\n",
        "`pipeline`, which will take care of the entire ASR pipeline,\n",
        "right from pre-processing the audio inputs to decoding the\n",
        "model predictions.\n",
        "\n",
        "Running the example below will generate a Gradio demo where we\n",
        "can record speech through the microphone of our computer and input it to\n",
        "our fine-tuned Whisper model to transcribe the corresponding text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ace3aa-1ef3-45cb-933f-6ddca037c5aa",
      "metadata": {
        "id": "e0ace3aa-1ef3-45cb-933f-6ddca037c5aa"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "pipe = pipeline(model=\"sanchit-gandhi/whisper-small-hi\")  # change to \"your-username/the-name-you-picked\"\n",
        "\n",
        "def transcribe(audio):\n",
        "    text = pipe(audio)[\"text\"]\n",
        "    return text\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=transcribe,\n",
        "    inputs=gr.Audio(source=\"microphone\", type=\"filepath\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Whisper Small Hindi\",\n",
        "    description=\"Realtime demo for Hindi speech recognition using a fine-tuned Whisper small model.\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca743fbd-602c-48d4-ba8d-a2fe60af64ba",
      "metadata": {
        "id": "ca743fbd-602c-48d4-ba8d-a2fe60af64ba"
      },
      "source": [
        "## Closing Remarks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f737783-2870-4e35-aa11-86a42d7d997a",
      "metadata": {
        "id": "7f737783-2870-4e35-aa11-86a42d7d997a"
      },
      "source": [
        "In this blog, we covered a step-by-step guide on fine-tuning Whisper for multilingual ASR\n",
        "using 🤗 Datasets, Transformers and the Hugging Face Hub. For more details on the Whisper model, the Common Voice dataset and the theory behind fine-tuning, refere to the accompanying [blog post](https://huggingface.co/blog/fine-tune-whisper). If you're interested in fine-tuning other\n",
        "Transformers models, both for English and multilingual ASR, be sure to check out the\n",
        "examples scripts at [examples/pytorch/speech-recognition](https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-recognition)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
